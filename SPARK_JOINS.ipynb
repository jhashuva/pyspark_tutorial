{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Set spark environments\n",
    "os.environ['PYSPARK_PYTHON'] = r'C:\\Users\\room102sys2\\AppData\\Local\\Programs\\Python\\Python39'\n",
    "#os.environ['PYSPARK_DRIVER_PYTHON'] = r'C:\\Users\\room102sys2\\AppData\\Local\\Programs\\Python\\Python39\\Scripts\\jupyter'\n",
    "#os.environ['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('C:\\Program Files\\Spark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = SparkSession.builder.appName(\"Spark Joins\").getOrCreate()\n",
    "sc = sp.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate = sp.createDataFrame([\n",
    "    (0,\"Matei Zaharia\",1, [100]),\n",
    "    (1, \"Bill Chambers\",0,[500, 250, 100]),\n",
    "    (2,\"JOSHUA U\",1,[250,100])\n",
    "]).toDF(\"id\",\"name\",\"graduate_program\",\"spark_status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "graduateProgram = sp.createDataFrame([\n",
    "(0, \"Masters\", \"School of Information\", \"UC Berkeley\"),\n",
    "(2, \"Masters\", \"EECS\", \"UC Berkeley\"),\n",
    "(1, \"Ph.D.\", \"EECS\", \"UC Berkeley\")])\\\n",
    ".toDF(\"id\", \"degree\", \"department\", \"school\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparkStatus = sp.createDataFrame([\n",
    "(500, \"Vice President\"),\n",
    "(250, \"PMC Member\"),\n",
    "(100, \"Contributor\")])\\\n",
    ".toDF(\"id\", \"status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate.createOrReplaceTempView(\"candidate\")\n",
    "graduateProgram.createOrReplaceTempView(\"graduateProgram\")\n",
    "sparkStatus.createOrReplaceTempView(\"sparkStatus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inner Joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "joinExpression = candidate[\"graduate_program\"] == graduateProgram['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keys that do not exist in both DataFrames will not show in the resulting DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrongJoinExpression = candidate[\"name\"] == graduateProgram[\"school\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inner joins are the default join, so we just need to specify our left DataFrame and join the right in the\n",
    "JOIN expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a=candidate.join(graduateProgram, joinExpression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "| id|         name|graduate_program|   spark_status| id| degree|          department|     school|\n",
      "+---+-------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "|  1|Bill Chambers|               0|[500, 250, 100]|  0|Masters|School of Informa...|UC Berkeley|\n",
      "|  0|Matei Zaharia|               1|          [100]|  1|  Ph.D.|                EECS|UC Berkeley|\n",
      "|  2|     JOSHUA U|               1|     [250, 100]|  1|  Ph.D.|                EECS|UC Berkeley|\n",
      "+---+-------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also specify this explicitly by passing, in a third parameter, the joinType:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "| id|         name|graduate_program|   spark_status| id| degree|          department|     school|\n",
      "+---+-------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "|  1|Bill Chambers|               0|[500, 250, 100]|  0|Masters|School of Informa...|UC Berkeley|\n",
      "|  0|Matei Zaharia|               1|          [100]|  1|  Ph.D.|                EECS|UC Berkeley|\n",
      "|  2|     JOSHUA U|               1|     [250, 100]|  1|  Ph.D.|                EECS|UC Berkeley|\n",
      "+---+-------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joinType = \"inner\"\n",
    "candidate.join(graduateProgram, joinExpression, joinType).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outer Joins\n",
    "- Outer joins evaluate the keys in both of the DataFrames or tables and includes (and joins together) the rows that evaluate to true or false.\n",
    "- If there is no equivalent row in either the left or right DataFrame, Spark will insert null:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "|  id|         name|graduate_program|   spark_status| id| degree|          department|     school|\n",
      "+----+-------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "|   1|Bill Chambers|               0|[500, 250, 100]|  0|Masters|School of Informa...|UC Berkeley|\n",
      "|   0|Matei Zaharia|               1|          [100]|  1|  Ph.D.|                EECS|UC Berkeley|\n",
      "|   2|     JOSHUA U|               1|     [250, 100]|  1|  Ph.D.|                EECS|UC Berkeley|\n",
      "|null|         null|            null|           null|  2|Masters|                EECS|UC Berkeley|\n",
      "+----+-------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joinType = \"outer\"\n",
    "candidate.join(graduateProgram, joinExpression, joinType).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Left Outer Joins\n",
    "- Left outer joins evaluate the keys in both of the DataFrames or tables and includes all rows from the left DataFrame as well as any rows in the right DataFrame that have a match in the left DataFrame.\n",
    "- If there is no equivalent row in the right DataFrame, Spark will insert `null`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------------+-----------+----+-------------+----------------+---------------+\n",
      "| id| degree|          department|     school|  id|         name|graduate_program|   spark_status|\n",
      "+---+-------+--------------------+-----------+----+-------------+----------------+---------------+\n",
      "|  0|Masters|School of Informa...|UC Berkeley|   1|Bill Chambers|               0|[500, 250, 100]|\n",
      "|  1|  Ph.D.|                EECS|UC Berkeley|   0|Matei Zaharia|               1|          [100]|\n",
      "|  1|  Ph.D.|                EECS|UC Berkeley|   2|     JOSHUA U|               1|     [250, 100]|\n",
      "|  2|Masters|                EECS|UC Berkeley|null|         null|            null|           null|\n",
      "+---+-------+--------------------+-----------+----+-------------+----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joinType = \"left_outer\"\n",
    "graduateProgram.join(candidate, joinExpression, joinType).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Right Outer Joins\n",
    "- Right outer joins evaluate the keys in both of the DataFrames or tables and includes all rows from the right DataFrame as well as any rows in the left DataFrame that have a match in the right DataFrame.\n",
    "- If there is no equivalent row in the left DataFrame, Spark will insert `null`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "|  id|         name|graduate_program|   spark_status| id| degree|          department|     school|\n",
      "+----+-------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "|   1|Bill Chambers|               0|[500, 250, 100]|  0|Masters|School of Informa...|UC Berkeley|\n",
      "|   0|Matei Zaharia|               1|          [100]|  1|  Ph.D.|                EECS|UC Berkeley|\n",
      "|   2|     JOSHUA U|               1|     [250, 100]|  1|  Ph.D.|                EECS|UC Berkeley|\n",
      "|null|         null|            null|           null|  2|Masters|                EECS|UC Berkeley|\n",
      "+----+-------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joinType = \"right_outer\"\n",
    "candidate.join(graduateProgram, joinExpression, joinType).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Left Semi JOins\n",
    "- semi joins are a bit of a departure from the other joins.\n",
    "- They do not actually include any values from the right DataFrame. They only compare values to see if the value exists in the second DataFrame. If the value exists, those rows will be kept in the results, even if there are duplicate keys in the left DataFrame.\n",
    "- Think of left semi joins as filters on a DataFrame, as opposed to the function of a conventional join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------------+-----------+\n",
      "| id| degree|          department|     school|\n",
      "+---+-------+--------------------+-----------+\n",
      "|  0|Masters|School of Informa...|UC Berkeley|\n",
      "|  1|  Ph.D.|                EECS|UC Berkeley|\n",
      "+---+-------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joinType = \"left_semi\"\n",
    "graduateProgram.join(candidate, joinExpression, joinType).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradProgram2 = graduateProgram.union(sp.createDataFrame([\n",
    "    (0,\"Masters\",\"Duplicated Row\",\"Duplicated School\")\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradProgram2.createOrReplaceTempView(\"gradProgram2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------------+-----------------+\n",
      "| id| degree|          department|           school|\n",
      "+---+-------+--------------------+-----------------+\n",
      "|  0|Masters|School of Informa...|      UC Berkeley|\n",
      "|  1|  Ph.D.|                EECS|      UC Berkeley|\n",
      "|  0|Masters|      Duplicated Row|Duplicated School|\n",
      "+---+-------+--------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gradProgram2.join(candidate, joinExpression, joinType).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_5248/4019634124.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\ROOM10~1\\AppData\\Local\\Temp/ipykernel_5248/4019634124.py\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    SELECT * FROM gradProgram2 LEFT SEMI JOIN candidate ON gradProgram2.id = candidate.graduate_program\u001b[0m\n\u001b[1;37m                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "%SQL\n",
    "SELECT * FROM gradProgram2 LEFT SEMI JOIN candidate ON gradProgram2.id = candidate.graduate_program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Left Anti Joins\n",
    "- Left anti joins are the opposite of left semi joins. Like left semi joins, they do not actually include any values from the right DataFrame.\n",
    "- However, rather than keeping the values that exist in the second DataFrame, they keep only the values that do not have a corresponding key in the second DataFrame.\n",
    "- Think of anti joins as a NOT IN SQL-style filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----------+-----------+\n",
      "| id| degree|department|     school|\n",
      "+---+-------+----------+-----------+\n",
      "|  2|Masters|      EECS|UC Berkeley|\n",
      "+---+-------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joinType = \"left_anti\"\n",
    "graduateProgram.join(candidate, joinExpression, joinType).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Joins\n",
    "- Natural joins make implicit guesses at the columns on which we would like join.\n",
    "- It finds matching columns and returns the results. \n",
    "- Left, right, and outer natural joins are all supported."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Warning                                                                                                                 \n",
    "Implicit is always dangerous!. The following query will give us incorrect results because the two DataFrames/tables share a   column name (id), but it means different things in the datasets. We should always use this join with caustion.               \n",
    "                                                                                                                             \n",
    "    -- in SQL                                                                                                                \n",
    "    SELECT * FROM graduateProgram NATURAL JOIN candidate                                                                     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross (Cartesian) Joins\n",
    "- Cross joins in simplest terms are inner joins that do not specify a predicate.\n",
    "- Cross joins will join every single row in the left DataFrame to ever single row in the right DataFrame. This will cause an abosolute explosion in the number of rows contained in the resulting DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------------+-----------+---+-------------+----------------+---------------+\n",
      "| id| degree|          department|     school| id|         name|graduate_program|   spark_status|\n",
      "+---+-------+--------------------+-----------+---+-------------+----------------+---------------+\n",
      "|  0|Masters|School of Informa...|UC Berkeley|  1|Bill Chambers|               0|[500, 250, 100]|\n",
      "|  1|  Ph.D.|                EECS|UC Berkeley|  0|Matei Zaharia|               1|          [100]|\n",
      "|  1|  Ph.D.|                EECS|UC Berkeley|  2|     JOSHUA U|               1|     [250, 100]|\n",
      "+---+-------+--------------------+-----------+---+-------------+----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joinType = \"cross\"\n",
    "graduateProgram.join(candidate, joinExpression, joinType).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--in SQL\n",
    "SELECT * FROM graduateProgram CROSS JOIN person\n",
    "   ON graduateProgram.id= candidate.graduate_program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We truly intended to have a cross-join, we can call that out explicitly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
